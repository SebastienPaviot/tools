<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face Swap with TensorFlow.js</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
</head>
<body>
  <h1>Face Swap Demo v0.61</h1>
  
  <!-- Upload source and target images -->
  <input type="file" id="sourceImage" accept="image/*" onchange="loadImage(event, 'source')">
  <input type="file" id="targetImage" accept="image/*" onchange="loadImage(event, 'target')">
  
  <canvas id="canvas" width="500" height="500"></canvas>
  
  <script>
    let sourceFaceLandmarks, targetFaceLandmarks;
    let sourceImg = new Image();
    let targetImg = new Image();
    let model;

    async function loadModel() {
     // model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh); // Modèle spécifique ici
     const detectorConfig = {
        runtime: 'tfjs',
        solutionPath: 'https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh',
      }
      model = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, detectorConfig);

    }

    function loadImage(event, type) {
      console.log("loadimage: " + type);
      const reader = new FileReader();
      reader.onload = function(e) {
        console.log("Image loaded successfully for type:", type); // Nouveau log ici
        if (type === 'source') {
          sourceImg.src = e.target.result;
        } else if (type === 'target') {
          targetImg.src = e.target.result;
        }
      };
      reader.onerror = function() {
        console.error("Error loading image for type:", type);
      };
      reader.readAsDataURL(event.target.files[0]);
    }

    async function detectLandmarks() {
      console.log("detectlandmarks");
      // Wait for both images to load
      await new Promise(resolve => {
        sourceImg.onload = targetImg.onload = resolve;
      });

      // Vérifier si l'image source et cible sont bien des HTMLImageElements
      if (!(sourceImg instanceof HTMLImageElement) || !(targetImg instanceof HTMLImageElement)) {
        console.error("L'une des images n'est pas un HTMLImageElement.");
        return;
      } else {
        console.log("image ok");
      }
      console.log(sourceImg);
      console.log(targetImg);

      // Detect landmarks for both images
      [sourceFaceLandmarks, targetFaceLandmarks] = await Promise.all([
          model.estimateFaces(sourceImg),
          model.estimateFaces(targetImg)
        ]);

      if (sourceFaceLandmarks.length > 0 && targetFaceLandmarks.length > 0) {
        swapFaces();
      } else {
        console.error("Face landmarks not detected");
      }
    }

    function swapFaces() {
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');

    // Dessiner l'image cible sur le canevas
    ctx.drawImage(targetImg, 0, 0, canvas.width, canvas.height);

    // Obtenez le premier ensemble de repères faciaux pour la source et la cible
    const sourceFace = sourceFaceLandmarks[0];
    const targetFace = targetFaceLandmarks[0];

    // Extraire les points clés (yeux, nez) pour l'alignement
    const sourceLeftEye = sourceFace.keypoints[33];
    const sourceRightEye = sourceFace.keypoints[263];
    const targetLeftEye = targetFace.keypoints[33];
    const targetRightEye = targetFace.keypoints[263];

    // Calculer l'échelle et la rotation
    const scale = calculateScale(sourceLeftEye, sourceRightEye, targetLeftEye, targetRightEye);
    const angle = calculateRotation(sourceLeftEye, sourceRightEye, targetLeftEye, targetRightEye);

    // Appliquer les transformations et dessiner le visage de la source sur l'image cible
    ctx.save();
    ctx.translate(targetLeftEye.x, targetLeftEye.y); // Positionner au niveau de l'œil gauche de la cible
    ctx.rotate(angle); // Appliquer la rotation
    ctx.scale(scale, scale); // Appliquer l'échelle
    ctx.drawImage(sourceImg, -sourceLeftEye.x, -sourceLeftEye.y); // Dessiner l'image de la source
    ctx.restore();
}

    function calculateScale(sourceLeftEye, sourceRightEye, targetLeftEye, targetRightEye) {
      const sourceDist = Math.hypot(sourceRightEye.x - sourceLeftEye.x, sourceRightEye.y - sourceLeftEye.y);
      const targetDist = Math.hypot(targetRightEye.x - targetLeftEye.x, targetRightEye.y - targetLeftEye.y);
      return targetDist / sourceDist;
    }

    function calculateRotation(sourceLeftEye, sourceRightEye, targetLeftEye, targetRightEye) {
      const sourceAngle = Math.atan2(sourceRightEye.y - sourceLeftEye.y, sourceRightEye.x - sourceLeftEye.x);
      const targetAngle = Math.atan2(targetRightEye.y - targetLeftEye.y, targetRightEye.x - targetLeftEye.x);
      return targetAngle - sourceAngle;
    }

    window.onload = async () => {
      await loadModel();
    };

    // Run face swap when both images are loaded
    document.getElementById('targetImage').addEventListener('change', detectLandmarks);
  </script>
</body>
</html>
