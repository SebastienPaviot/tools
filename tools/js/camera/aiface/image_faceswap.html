<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Face Swap with OpenCV.js and NumJS</title>
  <script src="https://docs.opencv.org/3.4/opencv.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/numjs/0.16.0/numjs.min.js"></script>
</head>
<body>
  <h1>Face Swap Demo v0.70</h1>
  <input type="file" id="sourceImage" accept="image/*" onchange="loadImage(event, 'source')">
  <input type="file" id="targetImage" accept="image/*" onchange="loadImage(event, 'target')">
  <canvas id="canvas" width="500" height="500"></canvas>
  <button id="but">go</button>
  <script>

function delay(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

async function attendreDeuxSecondes() {
  console.log("Attente de 2 secondes...");
  await delay(2000);
  console.log("2 secondes se sont écoulées");
}


    let sourceImg = new Image();
    let targetImg = new Image();
    let sourceFace, targetFace;

    function loadImage(event, type) {
  const file = event.target.files[0];
  const reader = new FileReader();

  reader.onload = function(e) {
    const img = new Image();
    img.src = e.target.result;
    
    img.onload = function() {
      const tempCanvas = document.createElement('canvas');
      tempCanvas.width = img.width;
      tempCanvas.height = img.height;
      const ctx = tempCanvas.getContext('2d');
      ctx.drawImage(img, 0, 0);

      if (type === 'source') {
        sourceImg = tempCanvas;
        console.log(sourceImg);
      } else if (type === 'target') {
        targetImg = tempCanvas;
        console.log(targetImg);
      }
    };
  };
  reader.readAsDataURL(file);
}

    async function detectFaces() {
      try {
     // attendreDeuxSecondes();
      console.log("detectfaces");
      console.log(sourceImg);
      const srcMat = cv.imread(sourceImg);
      console.log(srcMat);
      console.log(targetImg);
      const tgtMat = cv.imread(targetImg);
      console.log(tgtMat);
      console.log("classifier");
      //const faceCascade = new cv.CascadeClassifier();
      console.log("load model");
      let faceCascade = new cv.CascadeClassifier();

        // Assurez-vous que le fichier est accessible
        const modelPath = 'haarcascade_frontalface_default.xml'; // Utilisez un chemin correct pour ce fichier
        await faceCascade.load(modelPath); // Chargement du modèle

      console.log("loaded model");
      console.log(faceCascade);
      const srcGray = new cv.Mat();
      cv.cvtColor(srcMat, srcGray, cv.COLOR_RGBA2GRAY);
      const tgtGray = new cv.Mat();
      cv.cvtColor(tgtMat, tgtGray, cv.COLOR_RGBA2GRAY);
      console.log("cvt color");
      const srcFaces = new cv.RectVector();
      const tgtFaces = new cv.RectVector();
      console.log("init faces");
      faceCascade.detectMultiScale(srcGray, srcFaces, 1.1, 3, 0);
      faceCascade.detectMultiScale(tgtGray, tgtFaces, 1.1, 3, 0);
      console.log("multiscale detected");
      if (srcFaces.size() > 0 && tgtFaces.size() > 0) {
        console.log("faces ok");
        sourceFace = srcFaces.get(0);
        targetFace = tgtFaces.get(0);
        swapFaces(srcMat, tgtMat);
      } else {
        console.error("No faces detected in one or both images.");
      }

      srcMat.delete(); tgtMat.delete(); srcGray.delete(); tgtGray.delete();
      srcFaces.delete(); tgtFaces.delete();

    } catch (error) {
    console.error("Erreur lors de l'exécution d'OpenCV:", error);
}
    }

    function swapFaces(srcMat, tgtMat) {
      console.log("faceswap");
      const canvas = document.getElementById('canvas');
      const ctx = canvas.getContext('2d');
      canvas.width = targetImg.width;
      canvas.height = targetImg.height;

      const sourceRoi = srcMat.roi(sourceFace);
      const targetRoi = tgtMat.roi(targetFace);

      const srcPoints = nj.array([
        [sourceFace.x, sourceFace.y],
        [sourceFace.x + sourceFace.width, sourceFace.y],
        [sourceFace.x, sourceFace.y + sourceFace.height]
      ]);

      const tgtPoints = nj.array([
        [targetFace.x, targetFace.y],
        [targetFace.x + targetFace.width, targetFace.y],
        [targetFace.x, targetFace.y + targetFace.height]
      ]);

      const transformationMatrix = calculateAffineTransform(srcPoints, tgtPoints);

      const warpMat = new cv.Mat();
      cv.warpAffine(sourceRoi, targetRoi, transformationMatrix, targetRoi.size());

      cv.imshow(canvas, tgtMat);

      sourceRoi.delete(); targetRoi.delete(); warpMat.delete();
    }

    function calculateAffineTransform(srcPoints, tgtPoints) {
      const srcMean = srcPoints.mean(0);
      const tgtMean = tgtPoints.mean(0);
      const centeredSrc = srcPoints.subtract(srcMean);
      const centeredTgt = tgtPoints.subtract(tgtMean);

      const rotationMatrix = centeredTgt.transpose().dot(centeredSrc).tolist();
      const [U, , V] = nj.linalg.svd(rotationMatrix);

      const rotation = nj.dot(U, V);
      const scale = tgtPoints.norm() / srcPoints.norm();
      const translation = tgtMean.subtract(nj.dot(rotation, srcMean).multiply(scale));

      const affine = nj.concatenate([rotation.multiply(scale), translation.reshape(2, 1)], 1);
      return cv.matFromArray(2, 3, cv.CV_64F, affine.flatten().tolist());
    }

    document.getElementById('but').addEventListener('click', detectFaces);
  </script>
</body>
</html>
